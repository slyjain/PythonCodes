{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slyjain/PythonCodes/blob/main/coding_exercise_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES IMPLEMENTATION**"
      ],
      "metadata": {
        "id": "2sURYW4-ehSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is a simple implementation of the Naive Bayes.\n",
        "\n",
        "You have a few tasks to finish, they're in the comments. The code is in simple python, and it is an exercise to help you understand the algorithm better, and also give you some coding practice.\n",
        "\n",
        "Certainly! Here is a quick walkthrough of the code and the tasks:\n",
        "\n",
        "### Walkthrough of the Code\n",
        "\n",
        "#### Dataset and Labels\n",
        "```python\n",
        "# Given dataset\n",
        "X = [\n",
        "    [1, 0, 1],  # Sample 1\n",
        "    [1, 1, 0],  # Sample 2\n",
        "    [0, 0, 1],  # Sample 3\n",
        "    [1, 0, 0],  # Sample 4\n",
        "    [0, 1, 1],  # Sample 5\n",
        "    [0, 1, 0],  # Sample 6\n",
        "    [1, 1, 1],  # Sample 7\n",
        "    [0, 0, 0],  # Sample 8\n",
        "    [1, 0, 1],  # Sample 9\n",
        "    [1, 1, 1],  # Sample 10\n",
        "    [0, 1, 0],  # Sample 11\n",
        "    [1, 0, 0],  # Sample 12\n",
        "    [0, 0, 1],  # Sample 13\n",
        "    [0, 1, 1],  # Sample 14\n",
        "    [1, 1, 0],  # Sample 15\n",
        "]\n",
        "\n",
        "y = [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]  # Labels corresponding to the samples\n",
        "\n",
        "# Possible values of y\n",
        "y_values = list(set(y))\n",
        "```\n",
        "- `X` is the dataset containing 15 samples, each with three features.\n",
        "- `y` is the list of labels corresponding to each sample in `X`.\n",
        "- `y_values` contains the unique values of `y`, which represent the possible classes.\n",
        "\n",
        "#### Naive Bayes Prediction Function\n",
        "```python\n",
        "# Function to predict the class for a given input\n",
        "def predict_naive_bayes(x_test, X, y, y_values):\n",
        "    max_prob = -1\n",
        "    best_class = None\n",
        "    for y_val in y_values:  # For each value of y - we need P(X|Y) * P(Y)\n",
        "\n",
        "        # Calculate P(y)\n",
        "        count_y = ...  # Replace with the count of y_val in y\n",
        "        p_y = ...  # Replace with count_y divided by the length of y\n",
        "\n",
        "        # Calculate P(x|y)\n",
        "        p_x_given_y = 1.0\n",
        "        for feature_idx in range(len(x_test)):\n",
        "            count_feature_and_y = 0\n",
        "            for i in range(len(X)):\n",
        "                if y[i] == y_val and X[i][feature_idx] == x_test[feature_idx]:\n",
        "                    count_feature_and_y += 1\n",
        "            if count_y > 0:\n",
        "                p_x_given_y *= ...  # Replace with the conditional probability calculation\n",
        "\n",
        "        # Calculate P(y|x) = P(x|y) * P(y)\n",
        "        p_y_given_x = ...  # Replace with p_x_given_y multiplied by p_y\n",
        "\n",
        "        # Update max_prob and best_class\n",
        "        if p_y_given_x > max_prob:\n",
        "            max_prob = p_y_given_x\n",
        "            best_class = y_val\n",
        "    return best_class\n",
        "```\n",
        "- `predict_naive_bayes` is the function that will predict the class of a test input `x_test`.\n",
        "- `max_prob` and `best_class` are used to keep track of the highest posterior probability and the corresponding class.\n",
        "\n",
        "#### Test Input and Prediction\n",
        "```python\n",
        "# Test input\n",
        "X_test = [0, 1, 1]\n",
        "\n",
        "# Predicting the class for the test input\n",
        "prediction = predict_naive_bayes(X_test, X, y, y_values)\n",
        "print(\"Predicted class:\", prediction)\n",
        "```\n",
        "- `X_test` is the input sample for which we want to predict the class.\n",
        "- `predict_naive_bayes` is called with `X_test`, the dataset `X`, the labels `y`, and the possible values of `y`.\n",
        "- The predicted class is printed.\n",
        "\n",
        "### Reference for Naive Bayes Classifier\n",
        "\n",
        "#### Steps for Naive Bayes Classifier\n",
        "\n",
        "1. **Calculate Prior Probability \\( P(y) \\)**:\n",
        "   - Count the occurrences of each class in `y`.\n",
        "   - Divide the count by the total number of samples to get \\( P(y) \\).\n",
        "\n",
        "2. **Calculate Likelihood \\( P(x|y) \\)**:\n",
        "   - For each feature in the test sample, calculate the probability of that feature given the class label.\n",
        "   - Count how many times the feature value appears in the training data for the given class.\n",
        "   - Divide this count by the number of samples with the given class label.\n",
        "\n",
        "3. **Calculate Posterior Probability \\( P(y|x) \\)**:\n",
        "   - Multiply the prior probability \\( P(y) \\) by the likelihood \\( P(x|y) \\) for each class.\n",
        "   - This gives the posterior probability \\( P(y|x) \\).\n",
        "\n",
        "4. **Predict the Class**:\n",
        "   - The class with the highest posterior probability is chosen as the prediction.\n",
        "\n",
        "### Tasks for Students\n",
        "\n",
        "1. **Calculate \\( P(y) \\)**:\n",
        "   - Implement the calculation of the prior probability.\n",
        "\n",
        "2. **Calculate \\( P(x|y) \\)**:\n",
        "   - Implement the calculation of the likelihood for each feature given the class.\n",
        "\n",
        "3. **Calculate \\( P(y|x) \\)**:\n",
        "   - Implement the calculation of the posterior probability by multiplying the prior and likelihood.\n",
        "\n",
        "4. **Update max_prob and best_class**:\n",
        "   - Compare the calculated posterior probability with the current maximum and update if it's higher.\n",
        "\n",
        "This walkthrough provides a clear guide on how to complete the Naive Bayes classifier and understand its core concepts."
      ],
      "metadata": {
        "id": "kJs6jrFB2d82"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgeO4NMY_i65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skeleton code for Naive Bayes Classifier\n",
        "\n",
        "# Given dataset\n",
        "X = [\n",
        "    [1, 0, 1],  # Sample 1\n",
        "    [1, 1, 0],  # Sample 2\n",
        "    [0, 0, 1],  # Sample 3\n",
        "    [1, 0, 0],  # Sample 4\n",
        "    [0, 1, 1],  # Sample 5\n",
        "    [0, 1, 0],  # Sample 6\n",
        "    [1, 1, 1],  # Sample 7\n",
        "    [0, 0, 0],  # Sample 8\n",
        "    [1, 0, 1],  # Sample 9\n",
        "    [1, 1, 1],  # Sample 10\n",
        "    [0, 1, 0],  # Sample 11\n",
        "    [1, 0, 0],  # Sample 12\n",
        "    [0, 0, 1],  # Sample 13\n",
        "    [0, 1, 1],  # Sample 14\n",
        "    [1, 1, 0],  # Sample 15\n",
        "]\n",
        "\n",
        "y = [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]  # Labels corresponding to the samples\n",
        "\n",
        "# Possible values of y\n",
        "y_values = list(set(y))\n",
        "\n",
        "# Function to predict the class for a given input\n",
        "def predict_naive_bayes(x_test, X, y, y_values):\n",
        "    max_prob = -1\n",
        "    best_class = None\n",
        "    for y_val in y_values:  # For each value of y - we need P(X|Y) * P(Y)\n",
        "\n",
        "        # Task 1: Calculate P(y)\n",
        "        # Hint: P(y) is the number of times y_val appears in y divided by the total number of samples\n",
        "        count_y = len(y_values)  # Replace with the count of y_val in y\n",
        "        p_y = count_y/len(y)  # Replace with count_y divided by the length of y\n",
        "\n",
        "        # Task 2: Calculate P(x|y)\n",
        "        # Hint: Loop through each feature and calculate the conditional probability\n",
        "        p_x_given_y = 1.0\n",
        "        for feature_idx in range(len(x_test)):\n",
        "            count_feature_and_y = 0\n",
        "            for i in range(len(X)):\n",
        "                if y[i] == y_val and X[i][feature_idx] == x_test[feature_idx]:\n",
        "                    count_feature_and_y += 1\n",
        "            if count_y > 0:\n",
        "                p_x_given_y *= count_feature_and_y/len(X)  # Replace with the conditional probability calculation\n",
        "\n",
        "        # Task 3: Calculate P(y|x) = P(x|y) * P(y)\n",
        "        p_y_given_x = p_x_given_y*p_y  # Replace with p_x_given_y multiplied by p_y\n",
        "\n",
        "        # Task 4: Update max_prob and best_class\n",
        "        if p_y_given_x > max_prob:\n",
        "            max_prob = p_y_given_x\n",
        "            best_class = y_val\n",
        "    return best_class\n",
        "\n",
        "# Test input\n",
        "X_test = [0, 1, 1]\n",
        "\n",
        "# Predicting the class for the test input\n",
        "prediction = predict_naive_bayes(X_test, X, y, y_values)\n",
        "print(\"Predicted class:\", prediction)\n"
      ],
      "metadata": {
        "id": "q11ZTdeitjGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**"
      ],
      "metadata": {
        "id": "5PE8vlcP7oqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given dataset\n",
        "X = [\n",
        "    [1, 0, 1],  # Sample 1\n",
        "    [1, 1, 0],  # Sample 2\n",
        "    [0, 0, 1],  # Sample 3\n",
        "    [1, 0, 0],  # Sample 4\n",
        "    [0, 1, 1],  # Sample 5\n",
        "    [0, 1, 0],  # Sample 6\n",
        "    [1, 1, 1],  # Sample 7\n",
        "    [0, 0, 0],  # Sample 8\n",
        "    [1, 0, 1],  # Sample 9\n",
        "    [1, 1, 1],  # Sample 10\n",
        "    [0, 1, 0],  # Sample 11\n",
        "    [1, 0, 0],  # Sample 12\n",
        "    [0, 0, 1],  # Sample 13\n",
        "    [0, 1, 1],  # Sample 14\n",
        "    [1, 1, 0],  # Sample 15\n",
        "]\n",
        "\n",
        "y = [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]  # Labels corresponding to the samples\n",
        "\n",
        "# Possible values of y\n",
        "y_values = list(set(y))\n",
        "\n",
        "# Function to predict the class for a given input\n",
        "def predict_naive_bayes(x_test, X, y, y_values):\n",
        "      max_prob = -1\n",
        "      best_class = None\n",
        "      for y_val in y_values: #For each value of y - we need P(X|Y) * P(Y)\n",
        "\n",
        "          # Calculate P(y)\n",
        "          count_y = y.count(y_val)\n",
        "          p_y = count_y / len(y)\n",
        "\n",
        "          # Calculate P(x|y)\n",
        "          p_x_given_y = 1.0\n",
        "          for feature_idx in range(len(x_test)):\n",
        "              count_feature_and_y = 0\n",
        "              for i in range(len(X)):\n",
        "                if y[i] == y_val and X[i][feature_idx] == x_test[feature_idx]:\n",
        "                    count_feature_and_y += 1\n",
        "              if count_y > 0:\n",
        "                  p_x_given_y *= float(count_feature_and_y) / float(count_y)\n",
        "                    # print(count_feature_and_y, count_y)\n",
        "              # print(p_x_given_y, count_y)\n",
        "            # Calculate P(y|x) = P(x|y) * P(y)\n",
        "          p_y_given_x = p_x_given_y * p_y\n",
        "\n",
        "          if p_y_given_x > max_prob:\n",
        "              max_prob = p_y_given_x\n",
        "              best_class = y_val\n",
        "      return best_class\n",
        "\n",
        "# Test input\n",
        "X_test = [0, 1, 1]\n",
        "\n",
        "# Predicting the class for the test input\n",
        "prediction = predict_naive_bayes(X_test, X, y, y_values)\n",
        "print(\"Predicted classes:\", prediction)\n"
      ],
      "metadata": {
        "id": "y1VkQwDq7nPC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}